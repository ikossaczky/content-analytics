{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import re\n",
    "import pandas as pd\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sme_blog_links(first_page: int, last_page: int, subpage: str = ''):\n",
    "    sme_blog_links = []\n",
    "    for i in range(first_page, last_page):\n",
    "        source = requests.get(f'https://blog.sme.sk/{subpage}?page={i}').text\n",
    "        soup = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "        # Find all elements with href and class=\"title\"\n",
    "        elements = soup.select('a.title[href]')\n",
    "        \n",
    "        # Extract the links from the elements\n",
    "        links = [element['href'] for element in elements]\n",
    "\n",
    "        # Append the links to the list\n",
    "        sme_blog_links.extend(links)\n",
    "\n",
    "    # Add the base URL to the links\n",
    "    sme_blog_links = [f'https://blog.sme.sk{link}' for link in sme_blog_links]\n",
    "\n",
    "    # Remove duplicates\n",
    "    sme_blog_links = np.unique(sme_blog_links).tolist()\n",
    "\n",
    "    return sme_blog_links\n",
    "\n",
    "blogs = get_sme_blog_links(1, 20, 'najnovsie')\n",
    "blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with Slovak month names as keys and English month names as values\n",
    "slovak_to_english_months = {\n",
    "    'jan': 'Jan', 'feb': 'Feb', 'mar': 'Mar', 'apr': 'Apr', 'máj': 'May', 'jún': 'Jun',\n",
    "    'júl': 'Jul', 'aug': 'Aug', 'sep': 'Sep', 'okt': 'Oct', 'nov': 'Nov', 'dec': 'Dec'\n",
    "}\n",
    "\n",
    "def parse_sme_blog(url: str):\n",
    "    source = requests.get(url).text\n",
    "    soup = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "    # Parsing title\n",
    "    title = soup.find('h1').text\n",
    "\n",
    "    # Parsing perex\n",
    "    perex = soup.find('p', {'class': 'perex'}).text\n",
    "\n",
    "    # Parsing article body\n",
    "    article_body_element = soup.find('div', {'class': 'article-body-content'})\n",
    "    article_body = \"\\n\".join([element.text for element in article_body_element.find_all('p')]).strip()\n",
    "\n",
    "    # Parsing date\n",
    "    publication_datetime_str = soup.find('span', {\"class\": \"datetime datetime-long\"}).text\n",
    "    for sk, en in slovak_to_english_months.items():\n",
    "        publication_datetime_str = publication_datetime_str.replace(f\" {sk} \", f\" {en} \")\n",
    "    publication_datetime = (datetime\n",
    "                            .strptime(publication_datetime_str, \"%d. %b %Y o %H:%M\")\n",
    "                            .strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "    # Parsing likes\n",
    "    likes_str = soup.find('span', {\"class\": \"likes\"}).text\n",
    "    likes = int(re.sub(\"\\D\", \"\", likes_str))\n",
    "\n",
    "    # Parsing reads\n",
    "    reads_str = soup.find('span', {\"class\": \"read-count\"}).text\n",
    "    reads = int(re.sub(\"\\D\", \"\", reads_str))\n",
    "\n",
    "    # Parsing comments\n",
    "    comments_str = soup.find('small', {\"class\": \"count\"}).text\n",
    "    comments = int(re.sub(\"\\D\", \"\", comments_str))\n",
    "\n",
    "    # Parsing author\n",
    "    author_element = soup.select('a.name[href]')[0]\n",
    "    author_link = author_element[\"href\"]\n",
    "    author_name = author_element.text\n",
    "\n",
    "    return [\n",
    "        (\"url\", url),\n",
    "        (\"title\", title),\n",
    "        (\"perex\", perex),\n",
    "        (\"article_body\", article_body),\n",
    "        (\"publication_datetime\", publication_datetime),\n",
    "        (\"author_link\", author_link),\n",
    "        (\"author_name\", author_name),\n",
    "        (\"likes\", likes),\n",
    "        (\"reads\", reads),\n",
    "        (\"comments\", comments)\n",
    "    ]\n",
    "\n",
    "blog_data = [parse_sme_blog(b) for b in blogs[:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_rows =[tuple(property_value for property_name, property_value in blog_entry) for blog_entry in blog_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "BLOG_TABLE_COLUMNS = [\n",
    "        (\"url\", \"TEXT PRIMARY KEY\"),\n",
    "        (\"title\", \"TEXT\"),\n",
    "        (\"perex\", \"TEXT\"),\n",
    "        (\"article_body\", \"TEXT\"),\n",
    "        (\"publication_datetime\", \"TEXT\"),\n",
    "        (\"author_link\", \"TEXT\"),\n",
    "        (\"author_name\", \"TEXT\"),\n",
    "        (\"likes\", \"INTEGER\"),\n",
    "        (\"reads\", \"INTEGER\"),\n",
    "        (\"comments\", \"INTEGER\")\n",
    "    ]\n",
    "\n",
    "def create_table(db_name, table_name):\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    # Create table if not exists\n",
    "    c.execute(f'''\n",
    "        CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "            {\", \".join([f\"{col_name} {col_type}\" for col_name, col_type in BLOG_TABLE_COLUMNS])}\n",
    "        )\n",
    "    ''')\n",
    "\n",
    "    # Commit the changes and close the connection\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def insert_batch_into_table(db_name, table_name, rows):\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    c = conn.cursor()\n",
    "\n",
    "    # Insert a batch of rows into the table\n",
    "    c.executemany(f'''\n",
    "                  INSERT INTO {table_name} \n",
    "                  ({', '.join([col_name for col_name, _ in BLOG_TABLE_COLUMNS])}) \n",
    "                  VALUES \n",
    "                  ({', '.join(['?' for _ in range(len(BLOG_TABLE_COLUMNS))])})''', rows)\n",
    "\n",
    "    # Commit the changes and close the connection\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "db_name = \"/home/igork/private_data/sme_blogs.db\"\n",
    "table_name = \"blogs\"\n",
    "create_table(db_name, table_name)\n",
    "insert_batch_into_table(db_name, table_name, database_rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "igor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
